{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import timeit\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import re\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEMO = True\n",
    "WRITE_ERRORS_TO_FILE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if DEMO:\n",
    "    CHARTEVENTS_BY_ICUSTAY_ID = 'data_demo/parquet/'\n",
    "    REDUCED_CE_BY_ICUSTAY_ID = 'data_demo/samples/'\n",
    "    NUMERICAL_BY_ICUSTAY_ID = 'data_demo/samples_numerical/'\n",
    "    STATB_BY_ICUSTAY_ID = 'data_demo/samples_statB/'\n",
    "else:\n",
    "    CHARTEVENTS_BY_ICUSTAY_ID = 'data/parquet/'\n",
    "    REDUCED_CE_BY_ICUSTAY_ID = 'data/samples/'\n",
    "    NUMERICAL_BY_ICUSTAY_ID = 'data/samples_numerical/'\n",
    "    STATB_BY_ICUSTAY_ID = 'data/samples_statB/'\n",
    "\n",
    "\n",
    "CHARTEVENTS_FILENAME = 'mimic-iii/CHARTEVENTS.csv'\n",
    "READMISSION_FILENAME = 'data/readmission.csv'\n",
    "PARQUET_EXT = '.parquet'\n",
    "STEP_FAIL_FILE = 'Step6_failed.txt'\n",
    "SLOPE_TEXT = '_A'\n",
    "INTERCEPT_TEXT = '_B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chartevents_dir_list = os.listdir(REDUCED_CE_BY_ICUSTAY_ID)\n",
    "# len(chartevents_dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.read_parquet(REDUCED_CE_BY_ICUSTAY_ID + chartevents_dir_list[5])\n",
    "# test = test.reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Glascow](assets/images/GCS.jpg)\n",
    "\n",
    "https://www.firstaidforfree.com/glasgow-coma-scale-gcs-first-aiders/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|\tChart Event\t|\tDim\t|\tNormal\t| Initial dtype | Change to dtype |\n",
    "| --- | :--- | :--- | :--- | :--- |\n",
    "|\t1. Glasgow coma scale eye opening\t|\t4\t|\t4 Spontaneously\t| str | int |\n",
    "|\t2. Glasgow coma scale verbal response\t|\t5\t|\t5 Oriented\t| str | int |\n",
    "|\t3. Glasgow coma scale motor response\t|\t6\t|\t6 Obeys Commands\t| str | int |\n",
    "|\t4. Glasgow coma scale total\t|\t13\t|\t15\t| none/int | int |\n",
    "|\t5. Capillary refill rate\t|\t2\t|\tNormal < 3 secs\t| str | int |\n",
    "|\t6. Diastolic blood pressure\t|\t1\t|\t70\t| int | int |\n",
    "|\t7. Systolic blood pressure\t|\t1\t|\t105\t| int | int |\n",
    "|\t8. Mean blood pressure\t|\t1\t|\t87.5\t| int/float | int |\n",
    "|\t9. Heart Rate\t|\t1\t|\t80\t| int | int |\n",
    "|\t10. Glucose\t|\t1\t|\t85\t| int | int |\n",
    "|\t11. Fraction inspired oxygen\t|\t1\t|\t0.21\t| int/float | float? |\n",
    "|\t12. Oxygen saturation\t|\t1\t|\t97.5\t| int | int |\n",
    "|\t13. Respiratory rate\t|\t1\t|\t15\t| int | int |\n",
    "|\t14. Body Temperature\t|\t1\t|\t37\t| float | float |\n",
    "|\t15. pH\t|\t1\t|\t7.4\t| float | float |\n",
    "|\t16. Weight\t|\t1\t|\t80.7\t| float | float |\n",
    "|\t17. Height\t|\t1\t|\t168.8\t| float | float |\n",
    "\n",
    "\n",
    "Since there are so many `NaN` values, everything should just be a float?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_eye_map     = {'__missing__': np.NaN, '4 Spontaneously': '4', '1 No Response': '1', '2 To pain': '2', '3 To speech': '3', 'To Speech': '3', 'Spontaneously': '4', 'To Pain': '2'}\n",
    "gcs_motor_map   = {'__missing__': np.NaN, '6 Obeys Commands': '6', '5 Localizes Pain': '5', '1 No Response': '1', '4 Flex-withdraws': '4', '2 Abnorm extensn': '2', '3 Abnorm flexion': '3', 'Localizes Pain': '5', \n",
    "                    'Obeys Commands': '6', 'Flex-withdraws': '4', 'No response': '1', 'Abnormal Flexion': '3', 'Abnormal extension': '2'}\n",
    "gcs_verbal_map  = {'__missing__': np.NaN, '5 Oriented': '5', '1.0 ET/Trach': '1', '4 Confused': '4', '2 Incomp sounds': '2', '1 No Response': '1', '3 Inapprop words': '3', 'No Response-ETT': '1', \n",
    "                    'Oriented': '5', 'No Response': '1', 'Confused': '4', 'Incomprehensible sounds': '2', 'Inappropriate Words': '3'}\n",
    "capillary_map = {'__missing__': np.NaN, 'Brisk':'1', 'Delayed':'0', 'Comment':'0', 'Normal <3 secs':'1', 'Abnormal >3 secs':'0', 'Other/Remarks':'0', 'Normal <3 Seconds':'1', 'Abnormal >3 Seconds':'0'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_dtype_init = {'GCS_EYE': object, 'GCS_EYE_ID': np.float64, 'GCS_MOTOR': object, 'GCS_MOTOR_ID': np.float64, \n",
    "#                      'GCS_VERBAL': object, 'GCS_VERBAL_ID': np.float64, 'GCS_TOTAL': object, 'GCS_TOTAL_ID': np.float64, \n",
    "#                      'CAPILLARY_REFILL': object, 'CAPILLARY_REFILL_ID': np.float64, 'D_BLOOD_PRESSURE': object, \n",
    "#                      'D_BLOOD_PRESSURE_ID': np.float64, 'M_BLOOD_PRESSURE': object, 'M_BLOOD_PRESSURE_ID': np.float64, \n",
    "#                      'S_BLOOD_PRESSURE': object, 'S_BLOOD_PRESSURE_ID': np.float64, 'HEART_RATE': object, 'HEART_RATE_ID': np.float64, \n",
    "#                      'GLUCOSE': object, 'GLUCOSE_ID': np.float64, 'FRAC_OXYGEN': object, 'FRAC_OXYGEN_ID': object, 'O2_SAT': object, \n",
    "#                      'O2_SAT_ID': np.float64, 'RESP_RATE': object, 'RESP_RATE_ID': np.float64, 'BODY_TEMP': object, 'BODY_TEMP_ID': np.float64, \n",
    "#                      'PH': object, 'PH_ID': np.float64, 'WEIGHT': object, 'WEIGHT_ID': np.float64, 'HEIGHT': object, 'HEIGHT_ID': np.float64, \n",
    "#                      'GCS_EYE_IND': np.int8, 'GCS_MOTOR_IND': np.int8, 'GCS_VERBAL_IND': np.int8, 'GCS_TOTAL_IND': np.int8, \n",
    "#                      'CAPILLARY_REFILL_IND': np.int8, 'D_BLOOD_PRESSURE_IND': np.int8, 'M_BLOOD_PRESSURE_IND': np.int8, 'S_BLOOD_PRESSURE_IND': np.int8, \n",
    "#                      'HEART_RATE_IND': np.int8, 'GLUCOSE_IND': np.int8, 'FRAC_OXYGEN_IND': np.int8, 'O2_SAT_IND': np.int8, 'RESP_RATE_IND': np.int8, \n",
    "#                      'BODY_TEMP_IND': np.int8, 'PH_IND': np.int8, 'WEIGHT_IND': np.int8, 'HEIGHT_IND': np.int8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dtype_final = {'GCS_EYE': np.float64, 'GCS_EYE_ID': np.float64, 'GCS_MOTOR': np.float64, 'GCS_MOTOR_ID': np.float64, \n",
    "                     'GCS_VERBAL': np.float64, 'GCS_VERBAL_ID': np.float64, 'GCS_TOTAL': np.float64, 'GCS_TOTAL_ID': np.float64, \n",
    "                     'CAPILLARY_REFILL': np.float64, 'CAPILLARY_REFILL_ID': np.float64, 'D_BLOOD_PRESSURE': np.float64, \n",
    "                     'D_BLOOD_PRESSURE_ID': np.float64, 'M_BLOOD_PRESSURE': np.float64, 'M_BLOOD_PRESSURE_ID': np.float64, \n",
    "                     'S_BLOOD_PRESSURE': np.float64, 'S_BLOOD_PRESSURE_ID': np.float64, 'HEART_RATE': np.float64, 'HEART_RATE_ID': np.float64, \n",
    "                     'GLUCOSE': np.float64, 'GLUCOSE_ID': np.float64, 'FRAC_OXYGEN': np.float64, 'FRAC_OXYGEN_ID': np.float64, 'O2_SAT': np.float64, \n",
    "                     'O2_SAT_ID': np.float64, 'RESP_RATE': np.float64, 'RESP_RATE_ID': np.float64, 'BODY_TEMP': np.float64, 'BODY_TEMP_ID': np.float64, \n",
    "                     'PH': np.float64, 'PH_ID': np.float64, 'WEIGHT': np.float64, 'WEIGHT_ID': np.float64, 'HEIGHT': np.float64, 'HEIGHT_ID': np.float64, \n",
    "                     'GCS_EYE_IND': np.int8, 'GCS_MOTOR_IND': np.int8, 'GCS_VERBAL_IND': np.int8, 'GCS_TOTAL_IND': np.int8, \n",
    "                     'CAPILLARY_REFILL_IND': np.int8, 'D_BLOOD_PRESSURE_IND': np.int8, 'M_BLOOD_PRESSURE_IND': np.int8, 'S_BLOOD_PRESSURE_IND': np.int8, \n",
    "                     'HEART_RATE_IND': np.int8, 'GLUCOSE_IND': np.int8, 'FRAC_OXYGEN_IND': np.int8, 'O2_SAT_IND': np.int8, 'RESP_RATE_IND': np.int8, \n",
    "                     'BODY_TEMP_IND': np.int8, 'PH_IND': np.int8, 'WEIGHT_IND': np.int8, 'HEIGHT_IND': np.int8}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chartevents_dir_list = os.listdir(REDUCED_CE_BY_ICUSTAY_ID)\n",
    "len(chartevents_dir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.read_parquet(REDUCED_CE_BY_ICUSTAY_ID + chartevents_dir_list[0])\n",
    "# test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['D_BLOOD_PRESSURE', 'M_BLOOD_PRESSURE', 'S_BLOOD_PRESSURE', 'HEART_RATE', 'GLUCOSE', 'FRAC_OXYGEN', 'O2_SAT', 'RESP_RATE', 'BODY_TEMP', 'PH', 'WEIGHT', 'HEIGHT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_columns = []\n",
    "for col in numerical_columns:\n",
    "    stat_columns.append(col+SLOPE_TEXT)\n",
    "    stat_columns.append(col+INTERCEPT_TEXT)\n",
    "# stat_columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals\n",
    "\n",
    "1. Transform columns to numerical values\n",
    "2. Transform dtypes\n",
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "767acf769522447c82470a11f16a2089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "46\n",
      "45\n",
      "47\n",
      "8\n",
      "46\n",
      "47\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by LinearRegression.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mlist\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(feature_series))))\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m     18\u001b[0m y \u001b[39m=\u001b[39m feature_series\u001b[39m.\u001b[39mto_numpy()\n\u001b[1;32m---> 19\u001b[0m reg \u001b[39m=\u001b[39m LinearRegression()\u001b[39m.\u001b[39;49mfit(x, y)\n\u001b[0;32m     20\u001b[0m stat_df[col\u001b[39m+\u001b[39mSLOPE_TEXT] \u001b[39m=\u001b[39m reg\u001b[39m.\u001b[39mcoef_ \n\u001b[0;32m     21\u001b[0m stat_df[col\u001b[39m+\u001b[39mINTERCEPT_TEXT] \u001b[39m=\u001b[39m reg\u001b[39m.\u001b[39mintercept_\n",
      "File \u001b[1;32mc:\\Users\\bencsik.m\\stuff2\\1_Projects\\CS 598\\CS598CourseProject\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:648\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    644\u001b[0m n_jobs_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs\n\u001b[0;32m    646\u001b[0m accept_sparse \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositive \u001b[39melse\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcoo\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m--> 648\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    649\u001b[0m     X, y, accept_sparse\u001b[39m=\u001b[39;49maccept_sparse, y_numeric\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m    650\u001b[0m )\n\u001b[0;32m    652\u001b[0m sample_weight \u001b[39m=\u001b[39m _check_sample_weight(\n\u001b[0;32m    653\u001b[0m     sample_weight, X, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype, only_non_negative\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    654\u001b[0m )\n\u001b[0;32m    656\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[39m=\u001b[39m _preprocess_data(\n\u001b[0;32m    657\u001b[0m     X,\n\u001b[0;32m    658\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    661\u001b[0m     sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[0;32m    662\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\bencsik.m\\stuff2\\1_Projects\\CS 598\\CS598CourseProject\\.venv\\lib\\site-packages\\sklearn\\base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    583\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\bencsik.m\\stuff2\\1_Projects\\CS 598\\CS598CourseProject\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1109\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1110\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1111\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1112\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1113\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1114\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1115\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1116\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1117\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1118\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[0;32m   1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\bencsik.m\\stuff2\\1_Projects\\CS 598\\CS598CourseProject\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:931\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n\u001b[0;32m    930\u001b[0m     \u001b[39mif\u001b[39;00m n_samples \u001b[39m<\u001b[39m ensure_min_samples:\n\u001b[1;32m--> 931\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    932\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m sample(s) (shape=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) while a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    933\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m minimum of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m is required\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    934\u001b[0m             \u001b[39m%\u001b[39m (n_samples, array\u001b[39m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    935\u001b[0m         )\n\u001b[0;32m    937\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_features \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    938\u001b[0m     n_features \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by LinearRegression."
     ]
    }
   ],
   "source": [
    "failed = []\n",
    "for stay in tqdm(chartevents_dir_list, total=len(chartevents_dir_list)):\n",
    "    # try:\n",
    "        sample_df = pd.read_parquet(NUMERICAL_BY_ICUSTAY_ID + stay)\n",
    "        sample_df = sample_df.reset_index(drop=True).astype(sample_dtype_final)\n",
    "        \n",
    "        #numerical_df = sample_df[numerical_columns].dropna(axis=1,how='all')\n",
    "        bool_df = sample_df[numerical_columns].notnull()\n",
    "        bool_count = np.sum(bool_df, axis=0)\n",
    "        \n",
    "        stat_df = pd.DataFrame(columns=stat_columns)\n",
    "\n",
    "        for i, col in enumerate(sample_df.columns):\n",
    "            if sample_df[col].dtype == np.float64 and bool_count[i] > 1:\n",
    "                print(bool_count[i])\n",
    "                feature_series = sample_df[col].dropna(ignore_index=True)\n",
    "                x = np.array(list(range(len(feature_series)))).reshape(-1, 1)\n",
    "                y = feature_series.to_numpy()\n",
    "                reg = LinearRegression().fit(x, y)\n",
    "                stat_df[col+SLOPE_TEXT] = reg.coef_ \n",
    "                stat_df[col+INTERCEPT_TEXT] = reg.intercept_\n",
    "\n",
    "            elif sample_df[col].dtype == np.float64 and bool_count[i] == 1:\n",
    "                # TODO: set single value as intercept, slope as 0\n",
    "                pass\n",
    "\n",
    "        sample_df.to_parquet(STATB_BY_ICUSTAY_ID+stay)\n",
    "        break\n",
    "    # except Exception as e:\n",
    "    #     failed.append(stay)\n",
    "    #     failed.append(str(e))\n",
    "    #     continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ICUSTAY_ID=200001.parquet',\n",
       " 'Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by LinearRegression.',\n",
       " 'ICUSTAY_ID=200003.parquet',\n",
       " 'Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by LinearRegression.',\n",
       " 'ICUSTAY_ID=200006.parquet',\n",
       " 'Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by LinearRegression.',\n",
       " 'ICUSTAY_ID=200007.parquet',\n",
       " 'Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by LinearRegression.',\n",
       " 'ICUSTAY_ID=200009.parquet',\n",
       " 'Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by LinearRegression.',\n",
       " 'ICUSTAY_ID=200010.parquet',\n",
       " 'Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by LinearRegression.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if WRITE_ERRORS_TO_FILE:\n",
    "    with open(STEP_FAIL_FILE, 'w') as f:\n",
    "        for line in failed:\n",
    "            f.write(line)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
