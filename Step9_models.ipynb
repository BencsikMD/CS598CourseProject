{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEMO = False\n",
    "WRITE_ERRORS_TO_FILE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if DEMO:\n",
    "    CHARTEVENTS_BY_ICUSTAY_ID = 'data_demo/parquet/'\n",
    "    REDUCED_CE_BY_ICUSTAY_ID = 'data_demo/samples/'\n",
    "    NUMERICAL_BY_ICUSTAY_ID = 'data_demo/samples_numerical/'\n",
    "    STATB_BY_ICUSTAY_ID = 'data_demo/samples_statB/'\n",
    "    STATB_CSV_BY_ICUSTAY_ID = 'data_demo/samples_statB_csv/'\n",
    "else:\n",
    "    CHARTEVENTS_BY_ICUSTAY_ID = 'data/parquet/'\n",
    "    REDUCED_CE_BY_ICUSTAY_ID = 'data/samples/'\n",
    "    NUMERICAL_BY_ICUSTAY_ID = 'data/samples_numerical/'\n",
    "    STATB_BY_ICUSTAY_ID = 'data/samples_statB/'\n",
    "    DEMO_BY_ICUSTAY_ID = 'data/samples_demographics/'\n",
    "    ICD9_BY_ICUSTAY_ID = 'data/samples_icd9/'\n",
    "\n",
    "\n",
    "CHARTEVENTS_FILENAME = 'mimic-iii/CHARTEVENTS.csv'\n",
    "DIAGNOSES_FILENAME = 'mimic-iii/DIAGNOSES_ICD.csv'\n",
    "READMISSION_FILENAME = 'data/readmission.csv'\n",
    "EMBEDDED_FILENAME = 'resources/embedded.parquet'\n",
    "ANNOTATION_FILENAME = 'data/anotation.csv'\n",
    "STEP_FAIL_FILE = 'Step9_failed.txt'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_FOLDS = 5\n",
    "TEST_SIZE = 0.1\n",
    "RANDOM_STATE = 1234\n",
    "EPOCH = 50\n",
    "BATCH_SIZE = 1\n",
    "LEARNING_RATE = 0.001\n",
    "BETA = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linearRegression(torch.nn.Module):\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        super(linearRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(inputSize, outputSize,dtype=float)\n",
    "        #self.linear = torch.nn.Linear(inputSize, outputSize)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "    if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
    "        m.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadmissionDataset(Dataset):\n",
    "    def __init__(self, annotations_file, numerical_dir=None, statB_dir=None, icd9_dir=None, demo_dir=None):\n",
    "        self.labels = pd.read_csv(annotations_file)\n",
    "        self.numerical_dir = numerical_dir\n",
    "        self.statB_dir = statB_dir\n",
    "        self.icd9_dir = icd9_dir\n",
    "        self.demo_dir = demo_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.numerical_dir:\n",
    "            numerical_path = os.path.join(self.numerical_dir, 'ICUSTAY_ID='+str(self.labels.iloc[idx, 0]))\n",
    "            data = pd.read_parquet(numerical_path).to_numpy()\n",
    "        if self.statB_dir:\n",
    "            statB_path = os.path.join(self.statB_dir, 'ICUSTAY_ID='+str(self.labels.iloc[idx, 0]))\n",
    "            data = pd.read_parquet(statB_path).to_numpy().reshape(1,-1)\n",
    "            assert data.shape[1] == 29, f'Stay = {self.labels.iloc[idx, 0]}'\n",
    "        if self.icd9_dir:\n",
    "            icd9_path = os.path.join(self.icd9_dir, 'ICUSTAY_ID='+str(self.labels.iloc[idx, 0]))\n",
    "            icd9 = pd.read_parquet(icd9_path).reset_index(drop=True).to_numpy()\n",
    "            #if self.numerical_dir:\n",
    "            icd9 = np.vstack([icd9]*data.shape[0])\n",
    "            data = np.hstack([data, icd9]) \n",
    "            assert icd9.shape[1] == 300, f'Stay = {self.labels.iloc[idx, 0]}'\n",
    "        if self.demo_dir:\n",
    "            demo_path = os.path.join(self.demo_dir, 'ICUSTAY_ID='+str(self.labels.iloc[idx, 0]))\n",
    "            demo = pd.read_parquet(demo_path).reset_index(drop=True).to_numpy()\n",
    "            #if self.numerical_dir:\n",
    "            demo = np.vstack([demo]*data.shape[0])\n",
    "            data = np.hstack([data, demo])\n",
    "            assert demo.shape[1] == 4, f'Stay = {self.labels.iloc[idx, 0]}'\n",
    "\n",
    "        #data = torch.from_numpy(data.astype(float))\n",
    "        data = data.astype(float)\n",
    "        label = np.ndarray((1,1))\n",
    "        label[0,0] = self.labels.iloc[idx, 1]\n",
    "        \n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_np = pd.read_parquet(STATB_BY_ICUSTAY_ID+'ICUSTAY_ID=200001').to_numpy()\n",
    "# icd9_np = pd.read_parquet(ICD9_BY_ICUSTAY_ID+'ICUSTAY_ID=200001').to_numpy()\n",
    "# demo_df = pd.read_parquet(DEMO_BY_ICUSTAY_ID+'ICUSTAY_ID=200001').to_numpy()\n",
    "# data_np = np.hstack([data_np,icd9_np])\n",
    "# data_np.shape\n",
    "\n",
    "# demo_df = np.vstack([demo_df]*1)\n",
    "# demo_df = np.hstack([demo_df,demo_df])\n",
    "# demo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = ReadmissionDataset(ANNOTATION_FILENAME,NUMERICAL_BY_ICUSTAY_ID, STATB_BY_ICUSTAY_ID,ICD9_BY_ICUSTAY_ID, DEMO_BY_ICUSTAY_ID)\n",
    "dataset = ReadmissionDataset(ANNOTATION_FILENAME, numerical_dir=None, statB_dir=STATB_BY_ICUSTAY_ID, icd9_dir=ICD9_BY_ICUSTAY_ID, demo_dir=DEMO_BY_ICUSTAY_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Stay = 235557",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train, test \u001b[39m=\u001b[39m train_test_split(dataset, test_size\u001b[39m=\u001b[39;49mTEST_SIZE, random_state\u001b[39m=\u001b[39;49mRANDOM_STATE,shuffle\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m/media/Bencsik/SSD1/CS 598 Project/CS598CourseProject/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2585\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2581\u001b[0m     cv \u001b[39m=\u001b[39m CVClass(test_size\u001b[39m=\u001b[39mn_test, train_size\u001b[39m=\u001b[39mn_train, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m   2583\u001b[0m     train, test \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(cv\u001b[39m.\u001b[39msplit(X\u001b[39m=\u001b[39marrays[\u001b[39m0\u001b[39m], y\u001b[39m=\u001b[39mstratify))\n\u001b[0;32m-> 2585\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\n\u001b[1;32m   2586\u001b[0m     chain\u001b[39m.\u001b[39;49mfrom_iterable(\n\u001b[1;32m   2587\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[39mfor\u001b[39;49;00m a \u001b[39min\u001b[39;49;00m arrays\n\u001b[1;32m   2588\u001b[0m     )\n\u001b[1;32m   2589\u001b[0m )\n",
      "File \u001b[0;32m/media/Bencsik/SSD1/CS 598 Project/CS598CourseProject/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2587\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2581\u001b[0m     cv \u001b[39m=\u001b[39m CVClass(test_size\u001b[39m=\u001b[39mn_test, train_size\u001b[39m=\u001b[39mn_train, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m   2583\u001b[0m     train, test \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(cv\u001b[39m.\u001b[39msplit(X\u001b[39m=\u001b[39marrays[\u001b[39m0\u001b[39m], y\u001b[39m=\u001b[39mstratify))\n\u001b[1;32m   2585\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\n\u001b[1;32m   2586\u001b[0m     chain\u001b[39m.\u001b[39mfrom_iterable(\n\u001b[0;32m-> 2587\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m arrays\n\u001b[1;32m   2588\u001b[0m     )\n\u001b[1;32m   2589\u001b[0m )\n",
      "File \u001b[0;32m/media/Bencsik/SSD1/CS 598 Project/CS598CourseProject/.venv/lib/python3.10/site-packages/sklearn/utils/__init__.py:358\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[0;34m(X, indices, axis)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[39mreturn\u001b[39;00m _array_indexing(X, indices, indices_dtype, axis\u001b[39m=\u001b[39maxis)\n\u001b[1;32m    357\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 358\u001b[0m     \u001b[39mreturn\u001b[39;00m _list_indexing(X, indices, indices_dtype)\n",
      "File \u001b[0;32m/media/Bencsik/SSD1/CS 598 Project/CS598CourseProject/.venv/lib/python3.10/site-packages/sklearn/utils/__init__.py:212\u001b[0m, in \u001b[0;36m_list_indexing\u001b[0;34m(X, key, key_dtype)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(compress(X, key))\n\u001b[1;32m    211\u001b[0m \u001b[39m# key is a integer array-like of key\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m \u001b[39mreturn\u001b[39;00m [X[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m key]\n",
      "File \u001b[0;32m/media/Bencsik/SSD1/CS 598 Project/CS598CourseProject/.venv/lib/python3.10/site-packages/sklearn/utils/__init__.py:212\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(compress(X, key))\n\u001b[1;32m    211\u001b[0m \u001b[39m# key is a integer array-like of key\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m \u001b[39mreturn\u001b[39;00m [X[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m key]\n",
      "Cell \u001b[0;32mIn[7], line 19\u001b[0m, in \u001b[0;36mReadmissionDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     17\u001b[0m     statB_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatB_dir, \u001b[39m'\u001b[39m\u001b[39mICUSTAY_ID=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels\u001b[39m.\u001b[39miloc[idx, \u001b[39m0\u001b[39m]))\n\u001b[1;32m     18\u001b[0m     data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_parquet(statB_path)\u001b[39m.\u001b[39mto_numpy()\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m     \u001b[39massert\u001b[39;00m data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m29\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mStay = \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels\u001b[39m.\u001b[39miloc[idx,\u001b[39m \u001b[39m\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39micd9_dir:\n\u001b[1;32m     21\u001b[0m     icd9_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39micd9_dir, \u001b[39m'\u001b[39m\u001b[39mICUSTAY_ID=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels\u001b[39m.\u001b[39miloc[idx, \u001b[39m0\u001b[39m]))\n",
      "\u001b[0;31mAssertionError\u001b[0m: Stay = 235557"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(dataset, test_size=TEST_SIZE, random_state=RANDOM_STATE,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=K_FOLDS, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = linearRegression(dataset[0][0].shape[1], 1)\n",
    "criterion = torch.nn.MSELoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = [[] for i in range(K_FOLDS)]\n",
    "for fold, (train_index, valid_index) in enumerate(kfold.split(train)):\n",
    "    print('-'*50)\n",
    "    print('FOLD = ', fold+1)\n",
    "    # numpy arrays of indices are created from kfold\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_index)\n",
    "    valid_sampler = SubsetRandomSampler(valid_index)\n",
    "\n",
    "    train_dataloader = DataLoader(train, batch_size=None, shuffle=False, sampler=train_sampler)\n",
    "    valid_dataloader = DataLoader(train, batch_size=None, shuffle=False, sampler=valid_sampler)\n",
    "\n",
    "    model.apply(reset_weights)\n",
    "\n",
    "    for epoch in range(EPOCH):\n",
    "        current_loss = 0.0\n",
    "        for i, data in enumerate(train_dataloader):\n",
    "            #print(i)\n",
    "            #print(data)\n",
    "            \n",
    "            x_input, y_actual = data\n",
    "            optimizer.zero_grad()\n",
    "            x_input = torch.nan_to_num(x_input)\n",
    "            #print(x_input)\n",
    "            y_predict = model(torch.nan_to_num(x_input))\n",
    "            #print(y_predict)\n",
    "            # print(y_actual)\n",
    "            loss = criterion(y_predict, y_actual)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            current_loss += loss.item()\n",
    "            #print('current loss = ',current_loss)\n",
    "            if i % 1000 == 0:\n",
    "                print('current loss = ',current_loss)\n",
    "        \n",
    "        loss_list[fold].append(current_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list[0], label='epoch loss 1')\n",
    "plt.plot(loss_list[1], label='epoch loss 2')\n",
    "plt.plot(loss_list[2], label='epoch loss 3')\n",
    "plt.plot(loss_list[3], label='epoch loss 4')\n",
    "plt.plot(loss_list[4], label='epoch loss 5')\n",
    "plt.xlabel('epoch')\n",
    "plt.title('LR Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,t in enumerate(train):\n",
    "    if train[i][0].shape != (1,333):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train[172][0].shape)\n",
    "print(train[1018][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
